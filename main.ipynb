{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "TEST_SIZE = 0.3\n",
    "K = 3\n",
    "\n",
    "class NN:\n",
    "\n",
    "    def __init__(self, trainingFeatures, trainingLabels) -> None:\n",
    "        self.trainingFeatures = trainingFeatures\n",
    "        self.trainingLabels = trainingLabels\n",
    "\n",
    "    def predict(self, tesingFeatures, k):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(self.trainingFeatures, self.trainingLabels)\n",
    "        label_prediction = classifier.predict(tesingFeatures)\n",
    "        return label_prediction\n",
    "\n",
    "        \"\"\"\n",
    "        Given a list of features vectors of testing examples\n",
    "        return the predicted class labels (list of either 0s or 1s)\n",
    "        using the k nearest neighbors\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename)  # data frame\n",
    "    \"\"\"\n",
    "    Load spam data from a CSV file `filename` and convert into a list of\n",
    "    features vectors and a list of target labels. Return a tuple (features, labels).\n",
    "\n",
    "    features vectors should be a list of lists, where each list contains the\n",
    "    57 features vectors\n",
    "\n",
    "    labels should be the corresponding list of labels, where each label\n",
    "    is 1 if spam, and 0 otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    return df.iloc[:, :-1].values, df.iloc[:, -1].values\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def preprocess(features):\n",
    "    \"\"\"\n",
    "    normalize each feature by subtracting the mean value in each\n",
    "    feature and dividing by the standard deviation\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def train_mlp_model(features, labels):\n",
    "    \"\"\"\n",
    "    Given a list of features lists and a list of labels, return a\n",
    "    fitted MLP model trained on the data using sklearn implementation.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def evaluate(labels, predictions):\n",
    "    \"\"\"\n",
    "    Given a list of actual labels and a list of predicted labels,\n",
    "    return (accuracy, precision, recall, f1).\n",
    "\n",
    "    Assume each label is either a 1 (positive) or 0 (negative).\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "# Check command-line arguments\n",
    "if len(sys.argv) != 2:\n",
    "    sys.exit(\"Usage: python template.py ./spambase.csv\")\n",
    "\n",
    "# Load data from spreadsheet and split into train and test sets\n",
    "features, labels = load_data(sys.argv[1])\n",
    "features = preprocess(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=TEST_SIZE)\n",
    "\n",
    "# Train a k-NN model and make predictions\n",
    "model_nn = NN(X_train, y_train)\n",
    "predictions = model_nn.predict(X_test, K)\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate(y_test, predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"**** 1-Nearest Neighbor Results ****\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train an MLP model and make predictions\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m train_mlp_model(\u001B[43mX_train\u001B[49m, y_train)\n\u001B[0;32m      3\u001B[0m predictions \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      4\u001B[0m accuracy, precision, recall, f1 \u001B[38;5;241m=\u001B[39m evaluate(y_test, predictions)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train an MLP model and make predictions\n",
    "model = train_mlp_model(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy, precision, recall, f1 = evaluate(y_test, predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"**** MLP Results ****\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hdec = [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,\n",
    "        0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,\n",
    "        0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,\n",
    "        0xaa, 0xbb, 0xcc, 0xdd, 0xee]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
